{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pandas exploration\n",
    "In this assignment you will select a data set and do some munging and analysis of it using `pandas`, Jupyter Notebooks, and associated Python-centric data science tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines ensure that `numpy` and `pandas` are installed in the notebook environment.  Depending on your system, this may not be necessary and may be removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the core data science libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the raw data\n",
    "In this section, you will import the raw data into a `pandas` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extract_date</th>\n",
       "      <th>specimen_date</th>\n",
       "      <th>Number_tested</th>\n",
       "      <th>Number_confirmed</th>\n",
       "      <th>Number_hospitalized</th>\n",
       "      <th>Number_deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04/29/2020</td>\n",
       "      <td>04/17/2020</td>\n",
       "      <td>9979</td>\n",
       "      <td>3386</td>\n",
       "      <td>527</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04/29/2020</td>\n",
       "      <td>02/08/2020</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04/29/2020</td>\n",
       "      <td>03/05/2020</td>\n",
       "      <td>63</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04/29/2020</td>\n",
       "      <td>04/09/2020</td>\n",
       "      <td>9019</td>\n",
       "      <td>4803</td>\n",
       "      <td>1253</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04/29/2020</td>\n",
       "      <td>04/03/2020</td>\n",
       "      <td>9389</td>\n",
       "      <td>5523</td>\n",
       "      <td>1688</td>\n",
       "      <td>582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176143</th>\n",
       "      <td>10/01/2021</td>\n",
       "      <td>11/18/2020</td>\n",
       "      <td>21551</td>\n",
       "      <td>2483</td>\n",
       "      <td>163</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176144</th>\n",
       "      <td>10/01/2021</td>\n",
       "      <td>03/17/2021</td>\n",
       "      <td>13961</td>\n",
       "      <td>1678</td>\n",
       "      <td>166</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176145</th>\n",
       "      <td>10/01/2021</td>\n",
       "      <td>03/09/2020</td>\n",
       "      <td>401</td>\n",
       "      <td>89</td>\n",
       "      <td>36</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176146</th>\n",
       "      <td>10/01/2021</td>\n",
       "      <td>09/10/2021</td>\n",
       "      <td>14573</td>\n",
       "      <td>503</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176147</th>\n",
       "      <td>10/01/2021</td>\n",
       "      <td>09/04/2020</td>\n",
       "      <td>18765</td>\n",
       "      <td>1648</td>\n",
       "      <td>147</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176148 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       extract_date specimen_date  Number_tested  Number_confirmed  \\\n",
       "0        04/29/2020    04/17/2020           9979              3386   \n",
       "1        04/29/2020    02/08/2020              1                 0   \n",
       "2        04/29/2020    03/05/2020             63                 5   \n",
       "3        04/29/2020    04/09/2020           9019              4803   \n",
       "4        04/29/2020    04/03/2020           9389              5523   \n",
       "...             ...           ...            ...               ...   \n",
       "176143   10/01/2021    11/18/2020          21551              2483   \n",
       "176144   10/01/2021    03/17/2021          13961              1678   \n",
       "176145   10/01/2021    03/09/2020            401                89   \n",
       "176146   10/01/2021    09/10/2021          14573               503   \n",
       "176147   10/01/2021    09/04/2020          18765              1648   \n",
       "\n",
       "        Number_hospitalized  Number_deaths  \n",
       "0                       527             96  \n",
       "1                         0              0  \n",
       "2                         3              1  \n",
       "3                      1253            386  \n",
       "4                      1688            582  \n",
       "...                     ...            ...  \n",
       "176143                  163             41  \n",
       "176144                  166             27  \n",
       "176145                   36             19  \n",
       "176146                   38              0  \n",
       "176147                  147             33  \n",
       "\n",
       "[176148 rows x 6 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# place your code into this Code cell\n",
    "df = pd.read_csv(\"/Users/brandongao/pandas-assignment/data/COVID-19_Outcomes_by_Testing_Cohorts__Cases__Hospitalizations__and_Deaths_20240430.csv\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: /Users/brandongao/pandas-assignment\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "current_directory = os.getcwd()\n",
    "print(\"Current Directory:\", current_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data inspection\n",
    "In this section, you will show enough of your data for a viewer to get a general sense of how the data is structured and any unique features of it.  Complete each of the indicated tasks in a Code cell, making sure to include a Markdown cell above each Code cell that explains what is being shown by the code.  \n",
    "- Show 5 rows, selected at random, from the data set.\n",
    "- Show each of the column names and their data types.\n",
    "- Show any unique features of your chosen data set.\n",
    "\n",
    "Feel free to add as many additional cells as you need to help explain the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       extract_date specimen_date  Number_tested  Number_confirmed  \\\n",
      "165307   09/13/2021    07/16/2021           8116               243   \n",
      "53680    01/27/2021    03/04/2020             33                 7   \n",
      "78684    03/29/2021    04/18/2020           6571              2500   \n",
      "4544     06/03/2020    03/12/2020           1568               401   \n",
      "17657    08/31/2020    05/17/2020           6042               347   \n",
      "\n",
      "        Number_hospitalized  Number_deaths  \n",
      "165307                   19              1  \n",
      "53680                    16              2  \n",
      "78684                   613            216  \n",
      "4544                     97             31  \n",
      "17657                    59              9  \n"
     ]
    }
   ],
   "source": [
    "#Show 5 rows, selected at random, from the data set.\n",
    "print(df.sample(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract_date           object\n",
      "specimen_date          object\n",
      "Number_tested           int64\n",
      "Number_confirmed        int64\n",
      "Number_hospitalized     int64\n",
      "Number_deaths           int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Show each of the column names and their data types\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Number_tested  Number_confirmed  Number_hospitalized  Number_deaths\n",
      "count  176148.000000     176148.000000        176148.000000  176148.000000\n",
      "mean    11141.475714       1427.914680           234.946375      73.940686\n",
      "std      6413.050113       1368.222368           392.006729     160.110002\n",
      "min         1.000000          0.000000             0.000000       0.000000\n",
      "25%      6738.000000        371.000000            38.000000       4.000000\n",
      "50%     10885.000000       1135.000000           115.000000      21.000000\n",
      "75%     16448.000000       1960.000000           199.000000      44.000000\n",
      "max     24727.000000       6852.000000          2016.000000     923.000000\n"
     ]
    }
   ],
   "source": [
    "#Show any unique features of your chosen dataset\n",
    "#Showing the count,mean, standard deviation, minimum, 25% Percentile, 50% Percentile, 75% Percentile, Maximum of each of my numerical column\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data munging\n",
    "Place your **data munging** code and documentation within this section.  \n",
    "- Keep each of your Code cells short and focused on a single task.  \n",
    "- Include a Markdown cell above each code cell that describes what task the code within the code cell is performing.\n",
    "- Make as many code cells as you need to complete the munging - a few have been created for you to start with.\n",
    "- Display 5 sample rows of the modified data after each transformation so a viewer can see how the data has changed.\n",
    "\n",
    "**Note**: If you believe that your data set does not require any munging, please explain in detail.  Create Markdown cells that explain your thinking and create Code cells that show any specific structures of the data you refer to in your explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Checking if there is any null values in the data, because there are 0 null value for all columns. Hence, there is no null value in the data, no need to add or delete data for this reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract_date           0\n",
      "specimen_date          0\n",
      "Number_tested          0\n",
      "Number_confirmed       0\n",
      "Number_hospitalized    0\n",
      "Number_deaths          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking if there is any null values in the data\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.when I try to convert string dates from extract_date and specimen_date, an error appeared, which shows: OutOfBoundsDatetime: Out of bounds nanosecond timestamp: 2299-07-21 00:00:00 present at position 277\n",
    "### There appears to be an invalid date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OutOfBoundsDatetime",
     "evalue": "Out of bounds nanosecond timestamp: 2299-07-21 00:00:00 present at position 277",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfBoundsDatetime\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextract_date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextract_date\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspecimen_date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspecimen_date\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:1064\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1062\u001b[0m             result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mtz_localize(tz)\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, ABCSeries):\n\u001b[0;32m-> 1064\u001b[0m     cache_array \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_listlike\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1065\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cache_array\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m   1066\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:229\u001b[0m, in \u001b[0;36m_maybe_cache\u001b[0;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[1;32m    227\u001b[0m unique_dates \u001b[38;5;241m=\u001b[39m unique(arg)\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_dates) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(arg):\n\u001b[0;32m--> 229\u001b[0m     cache_dates \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43munique_dates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m# GH#45319\u001b[39;00m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:438\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m infer_datetime_format\n\u001b[1;32m    437\u001b[0m utc \u001b[38;5;241m=\u001b[39m tz \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutc\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 438\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mobjects_to_datetime64ns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m    \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequire_iso8601\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequire_iso8601\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n\u001b[1;32m    451\u001b[0m     dta \u001b[38;5;241m=\u001b[39m DatetimeArray(result, dtype\u001b[38;5;241m=\u001b[39mtz_to_dtype(tz_parsed))\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/arrays/datetimes.py:2177\u001b[0m, in \u001b[0;36mobjects_to_datetime64ns\u001b[0;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001b[0m\n\u001b[1;32m   2175\u001b[0m order: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m flags\u001b[38;5;241m.\u001b[39mf_contiguous \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2176\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2177\u001b[0m     result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mtslib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_to_datetime\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mK\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2179\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2182\u001b[0m \u001b[43m        \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequire_iso8601\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequire_iso8601\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_mixed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_mixed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2185\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2186\u001b[0m     result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mreshape(data\u001b[38;5;241m.\u001b[39mshape, order\u001b[38;5;241m=\u001b[39morder)\n\u001b[1;32m   2187\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOverflowError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   2188\u001b[0m     \u001b[38;5;66;03m# Exception is raised when a part of date is greater than 32 bit signed int\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/_libs/tslib.pyx:427\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/_libs/tslib.pyx:678\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/_libs/tslib.pyx:674\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/_libs/tslib.pyx:628\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/_libs/tslibs/conversion.pyx:391\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.conversion.convert_datetime_to_tsobject\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/_libs/tslibs/np_datetime.pyx:212\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.np_datetime.check_dts_bounds\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOutOfBoundsDatetime\u001b[0m: Out of bounds nanosecond timestamp: 2299-07-21 00:00:00 present at position 277"
     ]
    }
   ],
   "source": [
    "df['extract_date'] = pd.to_datetime(df['extract_date'])\n",
    "df['specimen_date'] = pd.to_datetime(df['specimen_date'])\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. We can directly convert the dates to datetime format if no error occurs. Otherwise, we can convert the out of bound data into a Not a Time dataformat, and remove the row containing the invalid date in by filtering out the NoT type using the pandas dropna() function. As a result, the invalid date with 2299-07-21 timestamp is removed, and the rest of the time is converted to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dates(df, date_columns):\n",
    "    for column in date_columns:\n",
    "        df[column] = pd.to_datetime(df[column], errors='coerce')\n",
    "    df = df.dropna(subset=date_columns)\n",
    "    return df\n",
    "\n",
    "date_columns = ['extract_date', 'specimen_date']\n",
    "df = filter_dates(df, date_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extract_date           datetime64[ns]\n",
      "specimen_date          datetime64[ns]\n",
      "Number_tested                   int64\n",
      "Number_confirmed                int64\n",
      "Number_hospitalized             int64\n",
      "Number_deaths                   int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# The data types for the dates are now datetime64\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       extract_date specimen_date  Number_tested  Number_confirmed  \\\n",
      "85218    2021-04-14    2020-08-27          15571              1198   \n",
      "114178   2021-05-05    2020-07-30          15540              1247   \n",
      "85870    2021-04-15    2020-09-09          18271              1358   \n",
      "64991    2021-02-26    2020-05-16           6675               751   \n",
      "46318    2021-01-02    2020-10-05          21015               904   \n",
      "\n",
      "        Number_hospitalized  Number_deaths  \n",
      "85218                    98             21  \n",
      "114178                  132             22  \n",
      "85870                   111             18  \n",
      "64991                   112             18  \n",
      "46318                    62              4  \n"
     ]
    }
   ],
   "source": [
    "#Display 5 sample rows of the modified data\n",
    "print(df.sample(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis\n",
    "Place your **data analysis** code and documentation within this section.\n",
    "- Perform at least 5 different statistical or other analyses of different aspects of the data.\n",
    "    - Your analyses must be specific and relevant to your chosen data set and show interesting aspects of it.\n",
    "    - Include at least one analysis that includes grouping rows by a shared attribute and performing some kind of statistical analysis on each group.\n",
    "    - Sort the data in at least 1 of your analyses, but sort on its own does not constitute an analysis on its own.\n",
    "- Keep each of your Code cells short and focused on a single task.\n",
    "- Include a Markdown cell above each Code cell that describes what task the code within the Code cell is performing.\n",
    "- Make as many code cells as you need to complete the analysis - a few have been created for you to start with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Grouping the specimen_date by months, finding the averages of numbers within the month for each column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Number_tested  Number_confirmed  Number_hospitalized  \\\n",
      "month_year                                                         \n",
      "2020-01          7.977763          1.684126             0.167984   \n",
      "2020-02          1.847248          0.338379             0.206728   \n",
      "2020-03       3615.830210       2213.245649           666.955855   \n",
      "2020-04       8856.352349       3835.653846           990.651136   \n",
      "2020-05      11928.370171       1367.050644           171.536572   \n",
      "2020-06      14825.359438        847.393032           102.010613   \n",
      "2020-07      14799.852372        872.221556            89.030133   \n",
      "2020-08      13930.214672        782.897495            74.494924   \n",
      "2020-09      14108.982818        856.066898            75.391153   \n",
      "2020-10      14268.919499        987.276745            86.617718   \n",
      "2020-11      16124.712973       1593.848939           122.578539   \n",
      "2020-12      16528.021757       2366.048633           191.883188   \n",
      "2021-01      16727.216811       2689.417854           225.204603   \n",
      "2021-02      11716.233752       1686.940728           177.953599   \n",
      "2021-03      12253.058804       1476.101795           146.142316   \n",
      "2021-04      11058.242004        893.797023            88.565480   \n",
      "2021-05       8084.159441        219.637053            27.354655   \n",
      "2021-06       6823.103912         86.683568            11.342410   \n",
      "2021-07       7148.942226        219.609601            17.621920   \n",
      "2021-08      10342.195262        535.244795            38.972003   \n",
      "2021-09       9893.437923        410.844244            26.406321   \n",
      "\n",
      "            Number_deaths  \n",
      "month_year                 \n",
      "2020-01          0.002813  \n",
      "2020-02          0.053517  \n",
      "2020-03        237.850767  \n",
      "2020-04        392.051045  \n",
      "2020-05         49.198659  \n",
      "2020-06         20.885823  \n",
      "2020-07         14.977154  \n",
      "2020-08         11.733421  \n",
      "2020-09         14.141290  \n",
      "2020-10         15.684834  \n",
      "2020-11         22.764056  \n",
      "2020-12         37.845026  \n",
      "2021-01         45.758647  \n",
      "2021-02         34.335293  \n",
      "2021-03         23.414923  \n",
      "2021-04         13.005432  \n",
      "2021-05          3.459607  \n",
      "2021-06          1.035994  \n",
      "2021-07          1.307562  \n",
      "2021-08          2.901651  \n",
      "2021-09          1.187359  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ym/tr9p7y314096r29j5qvndy4c0000gn/T/ipykernel_67036/364749671.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  monthly_data = df.groupby('month_year').mean()\n"
     ]
    }
   ],
   "source": [
    "df['month_year'] = df['specimen_date'].dt.to_period('M')\n",
    "monthly_data = df.groupby('month_year').mean()\n",
    "print(monthly_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Construct Correlation Matrix to discover the how much correlation are between the columns. Findings: the number_confirmed, number_hospitalized, number_deaths columns are highly correlated with each other, and the number_tested column has low correlation with all other three columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Number_tested  Number_confirmed  Number_hospitalized  \\\n",
      "Number_tested             1.000000          0.273451            -0.066410   \n",
      "Number_confirmed          0.273451          1.000000             0.873878   \n",
      "Number_hospitalized      -0.066410          0.873878             1.000000   \n",
      "Number_deaths            -0.114014          0.829976             0.987081   \n",
      "\n",
      "                     Number_deaths  \n",
      "Number_tested            -0.114014  \n",
      "Number_confirmed          0.829976  \n",
      "Number_hospitalized       0.987081  \n",
      "Number_deaths             1.000000  \n"
     ]
    }
   ],
   "source": [
    "correlation_matrix = df[['Number_tested', 'Number_confirmed', 'Number_hospitalized', 'Number_deaths']].corr()\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Find the top 5 days with the most number of tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       extract_date specimen_date  Number_tested  Number_confirmed  \\\n",
      "109825   2021-05-02    2021-01-04          24727              4207   \n",
      "97322    2021-05-05    2021-01-04          24727              4213   \n",
      "113567   2021-05-08    2021-01-04          24727              4217   \n",
      "112666   2021-05-04    2021-01-04          24726              4212   \n",
      "92282    2021-05-03    2021-01-04          24726              4210   \n",
      "\n",
      "        Number_hospitalized  Number_deaths month_year  \n",
      "109825                  289             48    2021-01  \n",
      "97322                   289             49    2021-01  \n",
      "113567                  289             49    2021-01  \n",
      "112666                  289             49    2021-01  \n",
      "92282                   289             49    2021-01  \n"
     ]
    }
   ],
   "source": [
    "top_testing_days = df.sort_values(by='Number_tested', ascending=False).head(5)\n",
    "print(top_testing_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.Total percentage of death out of the confirmed cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of confirmed cases resulting in death: 5.18%\n"
     ]
    }
   ],
   "source": [
    "total_confirmed = df['Number_confirmed'].sum()\n",
    "\n",
    "total_deaths = df['Number_deaths'].sum()\n",
    "\n",
    "death_rate = (total_deaths / total_confirmed) * 100\n",
    "print(f\"Percentage of confirmed cases resulting in death: {death_rate:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.Sort the data by highest number of death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       extract_date specimen_date  Number_tested  Number_confirmed  \\\n",
      "173987   2021-09-28    2020-04-06          10935              6851   \n",
      "175088   2021-09-30    2020-04-06          10935              6852   \n",
      "174632   2021-09-29    2020-04-06          10935              6852   \n",
      "175951   2021-10-01    2020-04-06          10935              6852   \n",
      "173091   2021-09-27    2020-04-06          10935              6851   \n",
      "\n",
      "        Number_hospitalized  Number_deaths month_year  \n",
      "173987                 1979            923    2020-04  \n",
      "175088                 1980            923    2020-04  \n",
      "174632                 1979            923    2020-04  \n",
      "175951                 1980            923    2020-04  \n",
      "173091                 1979            922    2020-04  \n"
     ]
    }
   ],
   "source": [
    "sorted_by_deaths = df.sort_values(by='Number_deaths', ascending=False)\n",
    "print(sorted_by_deaths.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualization\n",
    "In this section, you will create a few **visualizations** that show some of the insights you have gathered from this data.\n",
    "- Create at least 5 different visualizations, where each visualization shows different insights into the data.\n",
    "- Use at least 3 different visualization types (e.g. bar charts, line charts, stacked area charts, pie charts, etc)\n",
    "- Create a Markdown cell and a Code cell for each, where you explain and show the visualizations, respectively.\n",
    "- Create as many additional cells as you need to prepare the data for the visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "941c1a3237318875a4982e5656d95b5f7dbd757d44ba8036206372cf533b8aed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
